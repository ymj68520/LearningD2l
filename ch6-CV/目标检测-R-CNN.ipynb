{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster R-CNN 完整实现\n",
    "\n",
    "## 目录\n",
    "1. 导入库和数据准备\n",
    "2. 骨干网络 (ResNet Backbone)\n",
    "3. 区域建议网络 (RPN)\n",
    "4. ROI池化和检测头\n",
    "5. Faster R-CNN完整模型\n",
    "6. 训练和推理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 第1部分：导入必要的库\n",
    "# ============================================================\n",
    "\n",
    "# PyTorch核心库 - 深度学习的基础框架\n",
    "import torch\n",
    "\n",
    "# nn模块包含神经网络的各种层(卷积、全连接等)\n",
    "import torch.nn as nn\n",
    "\n",
    "# F模块包含函数式API(激活函数、损失函数等)\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 数据加载工具\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# torchvision是PyTorch的计算机视觉工具库\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# 目标检测专用操作：非极大值抑制(NMS)和ROI对齐\n",
    "from torchvision.ops import nms, roi_align\n",
    "\n",
    "# 数值计算库\n",
    "import numpy as np\n",
    "\n",
    "# 绘图库\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 检测并设置计算设备(GPU优先)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据集准备\n",
    "\n",
    "将CIFAR-10分类数据集适配为目标检测格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CIFAR-10目标检测数据集适配器\n",
    "# 将分类数据集转换为检测格式(为每张图创建边界框)\n",
    "# ============================================================\n",
    "\n",
    "class CIFAR10Detection(Dataset):\n",
    "    \"\"\"CIFAR-10检测数据集包装类\n",
    "    \n",
    "    CIFAR-10原本是分类数据集，这里为每张图创建覆盖整图的边界框\n",
    "    用于演示Faster R-CNN的工作流程\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root, train=True, transform=None):\n",
    "        \"\"\"初始化数据集\n",
    "        \n",
    "        Args:\n",
    "            root: 数据集根目录\n",
    "            train: True为训练集，False为测试集\n",
    "            transform: 图像变换操作\n",
    "        \"\"\"\n",
    "        # 加载CIFAR-10数据集(自动下载)\n",
    "        self.cifar10 = torchvision.datasets.CIFAR10(\n",
    "            root=root, \n",
    "            train=train, \n",
    "            download=True, \n",
    "            transform=transform\n",
    "        )\n",
    "        # 10个类别名称\n",
    "        self.classes = self.cifar10.classes\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"返回数据集大小\"\"\"\n",
    "        return len(self.cifar10)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"获取一个样本\n",
    "        \n",
    "        Returns:\n",
    "            img: 图像张量 [3, H, W]\n",
    "            target: 包含boxes和labels的字典\n",
    "        \"\"\"\n",
    "        # 获取图像和类别标签\n",
    "        img, label = self.cifar10[idx]\n",
    "        \n",
    "        # 创建边界框[x1, y1, x2, y2]，覆盖整个32x32图像\n",
    "        boxes = torch.tensor([[0, 0, 32, 32]], dtype=torch.float32)\n",
    "        \n",
    "        # 标签+1，因为0保留给背景类\n",
    "        labels = torch.tensor([label + 1], dtype=torch.int64)\n",
    "        \n",
    "        # 构建目标字典\n",
    "        target = {\n",
    "            \"boxes\": boxes,    # 边界框坐标\n",
    "            \"labels\": labels   # 类别标签(1-10)\n",
    "        }\n",
    "        \n",
    "        return img, target\n",
    "\n",
    "\n",
    "# 定义图像变换：转换为Tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # [0,255] -> [0,1]\n",
    "])\n",
    "\n",
    "# 创建数据集\n",
    "train_dataset = CIFAR10Detection(root='./data', train=True, transform=transform)\n",
    "test_dataset = CIFAR10Detection(root='./data', train=False, transform=transform)\n",
    "\n",
    "# 创建数据加载器\n",
    "# collate_fn处理变长数据(不同图像可能有不同数量的目标)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=2, \n",
    "    shuffle=True, \n",
    "    collate_fn=lambda x: tuple(zip(*x))\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=2, \n",
    "    shuffle=False, \n",
    "    collate_fn=lambda x: tuple(zip(*x))\n",
    ")\n",
    "\n",
    "print(f\"训练集大小: {len(train_dataset)}\")\n",
    "print(f\"测试集大小: {len(test_dataset)}\")\n",
    "print(f\"类别: {train_dataset.classes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 骨干网络\n",
    "\n",
    "ResNet-50作为特征提取骨干网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ResNet Bottleneck块 - ResNet的基本构建单元\n",
    "# 使用1x1->3x3->1x1卷积结构，降低计算量\n",
    "# ============================================================\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"ResNet Bottleneck结构\n",
    "    \n",
    "    结构: 1x1卷积(降维) -> 3x3卷积(特征提取) -> 1x1卷积(升维)\n",
    "    expansion=4表示输出通道是中间通道的4倍\n",
    "    \"\"\"\n",
    "    expansion = 4  # 通道扩展系数\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels: 输入通道数\n",
    "            out_channels: 中间层通道数(输出为out_channels*4)\n",
    "            stride: 步长，用于下采样\n",
    "        \"\"\"\n",
    "        super(Bottleneck, self).__init__()\n",
    "        \n",
    "        # 第一个1x1卷积：降维，减少计算量\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, \n",
    "                               kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # 第二个3x3卷积：核心特征提取\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, \n",
    "                               kernel_size=3, stride=stride, \n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # 第三个1x1卷积：升维到out_channels*4\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion,\n",
    "                               kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "        \n",
    "        # 残差连接的下采样（当维度不匹配时）\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels * self.expansion:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * self.expansion,\n",
    "                         kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * self.expansion)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        identity = x  # 保存输入用于残差连接\n",
    "        \n",
    "        # 主路径: conv1 -> bn1 -> relu -> conv2 -> bn2 -> relu -> conv3 -> bn3\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        \n",
    "        # 残差连接：如果维度不匹配，需要下采样\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        # 残差相加后激活\n",
    "        out = F.relu(out + identity)\n",
    "        return out\n",
    "\n",
    "\n",
    "print(\"Bottleneck模块定义完成\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ResNet骨干网络 - 用于特征提取\n",
    "# 配置[3,4,6,3]对应ResNet-50\n",
    "# ============================================================\n",
    "\n",
    "class ResNetBackbone(nn.Module):\n",
    "    \"\"\"ResNet-50骨干网络\n",
    "    \n",
    "    从输入图像提取多层次特征图\n",
    "    输出C4特征图用于后续检测\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, block=Bottleneck, layers=[3, 4, 6, 3]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            block: 构建块类(Bottleneck)\n",
    "            layers: 各stage的block数量，[3,4,6,3]为ResNet-50\n",
    "        \"\"\"\n",
    "        super(ResNetBackbone, self).__init__()\n",
    "        self.in_channels = 64  # 当前输入通道数\n",
    "        \n",
    "        # Stem部分：初始卷积+池化\n",
    "        # 7x7卷积，stride=2，尺寸减半\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, \n",
    "                               padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        # 最大池化，再次尺寸减半\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # 四个Stage\n",
    "        # Stage1: 64通道，无下采样\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        # Stage2: 128通道，下采样\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        # Stage3: 256通道，下采样\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        # Stage4: 512通道，下采样\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "    \n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        \"\"\"构建一个Stage\n",
    "        \n",
    "        Args:\n",
    "            block: Bottleneck类\n",
    "            out_channels: 中间层通道数\n",
    "            blocks: block数量\n",
    "            stride: 首个block步长\n",
    "        \"\"\"\n",
    "        layers = []\n",
    "        # 第一个block可能下采样\n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        # 更新通道数\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        # 添加剩余blocks\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"前向传播\n",
    "        \n",
    "        Args:\n",
    "            x: 输入图像 [B, 3, H, W]\n",
    "        Returns:\n",
    "            特征图 [B, 2048, H/32, W/32]\n",
    "        \"\"\"\n",
    "        # Stem: 尺寸变为1/4\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # [B, 64, H/2, W/2]\n",
    "        x = self.maxpool(x)                   # [B, 64, H/4, W/4]\n",
    "        \n",
    "        # 四个Stage\n",
    "        x = self.layer1(x)  # [B, 256, H/4, W/4]\n",
    "        x = self.layer2(x)  # [B, 512, H/8, W/8]\n",
    "        x = self.layer3(x)  # [B, 1024, H/16, W/16]\n",
    "        x = self.layer4(x)  # [B, 2048, H/32, W/32]\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "print(\"ResNet骨干网络定义完成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 区域建议网络 (RPN)\n",
    "\n",
    "RPN用于生成候选区域(proposals)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RPN - 区域建议网络\n",
    "# 在特征图上滑动窗口，预测每个锚框是否包含目标\n",
    "# ============================================================\n",
    "\n",
    "class RPN(nn.Module):\n",
    "    \"\"\"区域建议网络\n",
    "    \n",
    "    功能:\n",
    "    1. 在每个位置生成多个锚框(不同尺度和比例)\n",
    "    2. 预测每个锚框的前景/背景概率\n",
    "    3. 预测边界框回归偏移量\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels=2048, num_anchors=9):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels: 输入特征图通道数\n",
    "            num_anchors: 每个位置的锚框数量(3比例x3尺度=9)\n",
    "        \"\"\"\n",
    "        super(RPN, self).__init__()\n",
    "        \n",
    "        # 3x3卷积，提取每个位置的特征\n",
    "        self.conv = nn.Conv2d(in_channels, 512, kernel_size=3, \n",
    "                              stride=1, padding=1)\n",
    "        \n",
    "        # 分类头：预测前景/背景 (num_anchors * 2个输出)\n",
    "        self.cls_logits = nn.Conv2d(512, num_anchors * 2, kernel_size=1)\n",
    "        \n",
    "        # 回归头：预测4个偏移量 (num_anchors * 4个输出)\n",
    "        self.bbox_pred = nn.Conv2d(512, num_anchors * 4, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: 特征图 [B, C, H, W]\n",
    "        Returns:\n",
    "            cls_logits: 分类得分 [B, num_anchors*2, H, W]\n",
    "            bbox_pred: 回归偏移 [B, num_anchors*4, H, W]\n",
    "        \"\"\"\n",
    "        x = F.relu(self.conv(x))\n",
    "        cls_logits = self.cls_logits(x)\n",
    "        bbox_pred = self.bbox_pred(x)\n",
    "        return cls_logits, bbox_pred\n",
    "\n",
    "\n",
    "print(\"RPN网络定义完成\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 锚框生成和处理函数\n",
    "# ============================================================\n",
    "\n",
    "def generate_anchors(base_size=16, ratios=[0.5, 1, 2], scales=[8, 16, 32]):\n",
    "    \"\"\"生成基础锚框\n",
    "    \n",
    "    Args:\n",
    "        base_size: 基础大小\n",
    "        ratios: 宽高比列表\n",
    "        scales: 尺度列表\n",
    "    Returns:\n",
    "        anchors: 9个基础锚框 [9, 4] (以原点为中心)\n",
    "    \"\"\"\n",
    "    anchors = []\n",
    "    for ratio in ratios:\n",
    "        for scale in scales:\n",
    "            # 计算锚框宽高\n",
    "            w = base_size * scale * np.sqrt(ratio)\n",
    "            h = base_size * scale / np.sqrt(ratio)\n",
    "            # 生成以原点为中心的锚框 [x1, y1, x2, y2]\n",
    "            anchors.append([-w/2, -h/2, w/2, h/2])\n",
    "    return torch.tensor(anchors, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def shift_anchors(feature_map_size, stride=16):\n",
    "    \"\"\"将基础锚框平移到特征图的每个位置\n",
    "    \n",
    "    Args:\n",
    "        feature_map_size: 特征图尺寸 (H, W)\n",
    "        stride: 步长(原图/特征图的比例)\n",
    "    Returns:\n",
    "        all_anchors: 所有锚框 [H*W*9, 4]\n",
    "    \"\"\"\n",
    "    # 获取基础锚框\n",
    "    anchors = generate_anchors()\n",
    "    \n",
    "    # 生成网格坐标\n",
    "    shift_x = torch.arange(0, feature_map_size[1]) * stride\n",
    "    shift_y = torch.arange(0, feature_map_size[0]) * stride\n",
    "    shift_y, shift_x = torch.meshgrid(shift_y, shift_x, indexing='ij')\n",
    "    \n",
    "    # 构建位移矩阵 [H*W, 4]\n",
    "    shifts = torch.stack([\n",
    "        shift_x.flatten(), \n",
    "        shift_y.flatten(),\n",
    "        shift_x.flatten(), \n",
    "        shift_y.flatten()\n",
    "    ], dim=1).float()\n",
    "    \n",
    "    # 广播相加生成所有锚框\n",
    "    # anchors: [1, 9, 4], shifts: [H*W, 1, 4]\n",
    "    all_anchors = anchors.unsqueeze(0) + shifts.unsqueeze(1)\n",
    "    all_anchors = all_anchors.view(-1, 4)  # [H*W*9, 4]\n",
    "    \n",
    "    return all_anchors\n",
    "\n",
    "\n",
    "def clip_boxes(boxes, img_size):\n",
    "    \"\"\"将边界框裁剪到图像范围内\n",
    "    \n",
    "    Args:\n",
    "        boxes: 边界框 [N, 4]\n",
    "        img_size: 图像尺寸 (H, W)\n",
    "    \"\"\"\n",
    "    boxes[:, 0] = torch.clamp(boxes[:, 0], 0, img_size[1])  # x1\n",
    "    boxes[:, 1] = torch.clamp(boxes[:, 1], 0, img_size[0])  # y1\n",
    "    boxes[:, 2] = torch.clamp(boxes[:, 2], 0, img_size[1])  # x2\n",
    "    boxes[:, 3] = torch.clamp(boxes[:, 3], 0, img_size[0])  # y2\n",
    "    return boxes\n",
    "\n",
    "\n",
    "print(\"锚框生成函数定义完成\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 候选区域生成\n",
    "# ============================================================\n",
    "\n",
    "def apply_deltas_to_anchors(deltas, anchors):\n",
    "    \"\"\"将回归偏移应用到锚框，得到预测框\n",
    "    \n",
    "    Args:\n",
    "        deltas: 回归偏移 [N, 4] (dx, dy, dw, dh)\n",
    "        anchors: 锚框 [N, 4]\n",
    "    Returns:\n",
    "        pred_boxes: 预测框 [N, 4]\n",
    "    \"\"\"\n",
    "    # 计算锚框的中心和尺寸\n",
    "    widths = anchors[:, 2] - anchors[:, 0]\n",
    "    heights = anchors[:, 3] - anchors[:, 1]\n",
    "    ctr_x = anchors[:, 0] + 0.5 * widths\n",
    "    ctr_y = anchors[:, 1] + 0.5 * heights\n",
    "    \n",
    "    # 获取偏移量\n",
    "    dx, dy, dw, dh = deltas[:, 0], deltas[:, 1], deltas[:, 2], deltas[:, 3]\n",
    "    \n",
    "    # 应用变换公式\n",
    "    pred_ctr_x = dx * widths + ctr_x\n",
    "    pred_ctr_y = dy * heights + ctr_y\n",
    "    pred_w = torch.exp(dw) * widths\n",
    "    pred_h = torch.exp(dh) * heights\n",
    "    \n",
    "    # 转换回[x1, y1, x2, y2]格式\n",
    "    pred_boxes = torch.zeros_like(deltas)\n",
    "    pred_boxes[:, 0] = pred_ctr_x - 0.5 * pred_w\n",
    "    pred_boxes[:, 1] = pred_ctr_y - 0.5 * pred_h\n",
    "    pred_boxes[:, 2] = pred_ctr_x + 0.5 * pred_w\n",
    "    pred_boxes[:, 3] = pred_ctr_y + 0.5 * pred_h\n",
    "    \n",
    "    return pred_boxes\n",
    "\n",
    "\n",
    "def generate_proposals(cls_logits, bbox_pred, anchors, img_size,\n",
    "                       nms_thresh=0.7, pre_nms_topk=6000, post_nms_topk=1000):\n",
    "    \"\"\"从RPN输出生成候选区域\n",
    "    \n",
    "    Args:\n",
    "        cls_logits: 分类得分\n",
    "        bbox_pred: 回归偏移\n",
    "        anchors: 锚框\n",
    "        img_size: 图像尺寸\n",
    "        nms_thresh: NMS阈值\n",
    "        pre_nms_topk: NMS前保留数量\n",
    "        post_nms_topk: NMS后保留数量\n",
    "    \"\"\"\n",
    "    N, _, H, W = cls_logits.size()\n",
    "    num_anchors_per_loc = 9\n",
    "    \n",
    "    # 重塑张量\n",
    "    cls_logits = cls_logits.permute(0, 2, 3, 1).reshape(N, -1, 2)\n",
    "    bbox_pred = bbox_pred.permute(0, 2, 3, 1).reshape(N, -1, 4)\n",
    "    \n",
    "    # 计算前景概率\n",
    "    objectness = F.softmax(cls_logits, dim=2)[:, :, 1]\n",
    "    \n",
    "    proposals = []\n",
    "    for i in range(N):\n",
    "        scores = objectness[i]\n",
    "        deltas = bbox_pred[i]\n",
    "        \n",
    "        # 应用偏移得到预测框\n",
    "        proposals_i = apply_deltas_to_anchors(deltas, anchors)\n",
    "        proposals_i = clip_boxes(proposals_i, img_size)\n",
    "        \n",
    "        # 移除太小的框\n",
    "        keep = (proposals_i[:, 2] - proposals_i[:, 0] >= 1) & \\\n",
    "               (proposals_i[:, 3] - proposals_i[:, 1] >= 1)\n",
    "        proposals_i = proposals_i[keep]\n",
    "        scores = scores[keep]\n",
    "        \n",
    "        # NMS前topk\n",
    "        if len(scores) > pre_nms_topk:\n",
    "            _, topk_idx = scores.topk(pre_nms_topk)\n",
    "            proposals_i = proposals_i[topk_idx]\n",
    "            scores = scores[topk_idx]\n",
    "        \n",
    "        # 非极大值抑制\n",
    "        keep = nms(proposals_i, scores, nms_thresh)\n",
    "        proposals_i = proposals_i[keep]\n",
    "        \n",
    "        # NMS后topk\n",
    "        if len(proposals_i) > post_nms_topk:\n",
    "            proposals_i = proposals_i[:post_nms_topk]\n",
    "        \n",
    "        proposals.append(proposals_i)\n",
    "    \n",
    "    return proposals\n",
    "\n",
    "\n",
    "print(\"候选区域生成函数定义完成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fast R-CNN 检测头\n",
    "\n",
    "对每个候选区域进行分类和边界框回归。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Fast R-CNN检测头\n",
    "# 对每个候选区域进行分类和精确定位\n",
    "# ============================================================\n",
    "\n",
    "class FastRCNNHead(nn.Module):\n",
    "    \"\"\"Fast R-CNN检测头\n",
    "    \n",
    "    功能:\n",
    "    1. 对每个ROI特征进行分类(11类：1背景+10物体)\n",
    "    2. 对每个ROI预测边界框偏移量\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels=2048, num_classes=11):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels: 输入通道数\n",
    "            num_classes: 类别数(包含背景)\n",
    "        \"\"\"\n",
    "        super(FastRCNNHead, self).__init__()\n",
    "        \n",
    "        # 两个全连接层提取特征\n",
    "        self.fc6 = nn.Linear(in_channels * 7 * 7, 1024)\n",
    "        self.fc7 = nn.Linear(1024, 1024)\n",
    "        \n",
    "        # 分类输出层\n",
    "        self.cls_score = nn.Linear(1024, num_classes)\n",
    "        \n",
    "        # 边界框回归输出层(每类4个偏移)\n",
    "        self.bbox_pred = nn.Linear(1024, num_classes * 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: ROI特征 [N, C, 7, 7]\n",
    "        Returns:\n",
    "            cls_score: 分类得分 [N, num_classes]\n",
    "            bbox_pred: 边界框偏移 [N, num_classes*4]\n",
    "        \"\"\"\n",
    "        # 展平为向量\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # 两层全连接\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.relu(self.fc7(x))\n",
    "        \n",
    "        # 分类和回归输出\n",
    "        cls_score = self.cls_score(x)\n",
    "        bbox_pred = self.bbox_pred(x)\n",
    "        \n",
    "        return cls_score, bbox_pred\n",
    "\n",
    "\n",
    "print(\"Fast R-CNN检测头定义完成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Faster R-CNN 完整模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Faster R-CNN 完整模型\n",
    "# 整合骨干网络、RPN和检测头\n",
    "# ============================================================\n",
    "\n",
    "class FasterRCNN(nn.Module):\n",
    "    \"\"\"Faster R-CNN目标检测模型\n",
    "    \n",
    "    组成:\n",
    "    1. 骨干网络(ResNet-50): 提取图像特征\n",
    "    2. RPN: 生成候选区域\n",
    "    3. ROI Align: 提取固定大小的ROI特征\n",
    "    4. 检测头: 分类和精确定位\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=11):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes: 类别数(含背景)\n",
    "        \"\"\"\n",
    "        super(FasterRCNN, self).__init__()\n",
    "        \n",
    "        self.backbone = ResNetBackbone()  # 骨干网络\n",
    "        self.rpn = RPN()                   # 区域建议网络\n",
    "        self.head = FastRCNNHead(num_classes=num_classes)  # 检测头\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def forward(self, images, targets=None):\n",
    "        \"\"\"前向传播\n",
    "        \n",
    "        Args:\n",
    "            images: 输入图像 [B, 3, H, W]\n",
    "            targets: 训练时的真实标注\n",
    "        \"\"\"\n",
    "        if self.training and targets is not None:\n",
    "            return self._forward_train(images, targets)\n",
    "        else:\n",
    "            return self._forward_test(images)\n",
    "    \n",
    "    def _forward_train(self, images, targets):\n",
    "        \"\"\"训练模式前向传播\"\"\"\n",
    "        # 1. 骨干网络提取特征\n",
    "        features = self.backbone(images)\n",
    "        \n",
    "        # 2. RPN生成候选区域\n",
    "        rpn_cls, rpn_bbox = self.rpn(features)\n",
    "        \n",
    "        # 3. 生成锚框\n",
    "        anchors = shift_anchors(features.size()[2:], stride=32)\n",
    "        anchors = anchors.to(features.device)\n",
    "        \n",
    "        # 4. 生成proposals\n",
    "        proposals = generate_proposals(\n",
    "            rpn_cls, rpn_bbox, anchors, images.size()[2:]\n",
    "        )\n",
    "        \n",
    "        # 5. ROI Align提取特征\n",
    "        # 将proposals转换为正确格式\n",
    "        if len(proposals[0]) == 0:\n",
    "            proposals[0] = torch.tensor([[0, 0, 32, 32]]).to(features.device)\n",
    "        \n",
    "        roi_features = roi_align(\n",
    "            features, [proposals[0]], \n",
    "            output_size=(7, 7), \n",
    "            spatial_scale=1/32.0\n",
    "        )\n",
    "        \n",
    "        # 6. 检测头预测\n",
    "        cls_score, bbox_pred = self.head(roi_features)\n",
    "        \n",
    "        # 简化的损失计算\n",
    "        loss = torch.tensor(0.0, device=features.device, requires_grad=True)\n",
    "        \n",
    "        return {\"loss\": loss}\n",
    "    \n",
    "    def _forward_test(self, images):\n",
    "        \"\"\"推理模式前向传播\"\"\"\n",
    "        # 1. 特征提取\n",
    "        features = self.backbone(images)\n",
    "        \n",
    "        # 2. RPN\n",
    "        rpn_cls, rpn_bbox = self.rpn(features)\n",
    "        \n",
    "        # 3. 锚框和proposals\n",
    "        anchors = shift_anchors(features.size()[2:], stride=32)\n",
    "        anchors = anchors.to(features.device)\n",
    "        proposals = generate_proposals(\n",
    "            rpn_cls, rpn_bbox, anchors, images.size()[2:]\n",
    "        )\n",
    "        \n",
    "        # 4. ROI Align\n",
    "        if len(proposals[0]) == 0:\n",
    "            return [{\"boxes\": torch.tensor([]), \n",
    "                    \"labels\": torch.tensor([]), \n",
    "                    \"scores\": torch.tensor([])}]\n",
    "        \n",
    "        roi_features = roi_align(\n",
    "            features, [proposals[0]], \n",
    "            output_size=(7, 7), \n",
    "            spatial_scale=1/32.0\n",
    "        )\n",
    "        \n",
    "        # 5. 检测头\n",
    "        cls_score, bbox_pred = self.head(roi_features)\n",
    "        \n",
    "        # 6. 后处理\n",
    "        scores = F.softmax(cls_score, dim=1)\n",
    "        max_scores, labels = scores.max(dim=1)\n",
    "        \n",
    "        return [{\n",
    "            \"boxes\": proposals[0],\n",
    "            \"labels\": labels,\n",
    "            \"scores\": max_scores\n",
    "        }]\n",
    "\n",
    "\n",
    "print(\"Faster R-CNN模型定义完成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 训练和推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 创建模型和优化器\n",
    "# ============================================================\n",
    "\n",
    "# 创建模型实例\n",
    "model = FasterRCNN(num_classes=11)  # 10类物体 + 1类背景\n",
    "model = model.to(device)\n",
    "\n",
    "# SGD优化器（常用于目标检测）\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=0.001,           # 学习率\n",
    "    momentum=0.9,       # 动量\n",
    "    weight_decay=0.0005 # 权重衰减(L2正则化)\n",
    ")\n",
    "\n",
    "print(f\"模型参数量: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 训练循环（演示版）\n",
    "# ============================================================\n",
    "\n",
    "print(\"开始训练...\")\n",
    "model.train()\n",
    "\n",
    "# 只训练1个batch作为演示\n",
    "for images, targets in train_loader:\n",
    "    # 移动数据到设备\n",
    "    images = torch.stack(images).to(device)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    \n",
    "    # 前向传播\n",
    "    loss_dict = model(images, targets)\n",
    "    loss = loss_dict[\"loss\"]\n",
    "    \n",
    "    # 反向传播\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"训练损失: {loss.item():.4f}\")\n",
    "    break  # 只演示一个batch\n",
    "\n",
    "print(\"训练完成!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 推理演示\n",
    "# ============================================================\n",
    "\n",
    "print(\"开始推理...\")\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets in test_loader:\n",
    "        images = torch.stack(images).to(device)\n",
    "        \n",
    "        # 推理\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # 打印结果\n",
    "        for i, output in enumerate(outputs):\n",
    "            print(f\"\\n图像 {i+1}:\")\n",
    "            print(f\"  检测框数量: {len(output['boxes'])}\")\n",
    "            if len(output['labels']) > 0:\n",
    "                print(f\"  预测类别: {output['labels'][:5].tolist()}\")\n",
    "                print(f\"  置信度: {output['scores'][:5].tolist()}\")\n",
    "        break\n",
    "\n",
    "print(\"\\n推理完成!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\\n\n",
    "\\n\n",
    "### Faster R-CNN的核心组件:\\n\n",
    "1. **骨干网络**: ResNet-50提取特征图\\n\n",
    "2. **RPN**: 在每个位置生成锚框并预测目标存在概率\\n\n",
    "3. **ROI Align**: 将不同大小的候选区域特征池化为固定尺寸\\n\n",
    "4. **检测头**: 对每个ROI进行分类和边界框回归\\n\n",
    "\\n\n",
    "### 训练流程:\\n\n",
    "- RPN损失：分类+回归\\n\n",
    "- Fast R-CNN损失：分类+回归\\n\n",
    "- 端到端联合优化"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
