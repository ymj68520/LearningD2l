{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c5d3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "from tqdm.auto import tqdm \n",
    "from torch.utils.data import random_split\n",
    "from d2l import torch as d2l\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "base_dir = \"classify-leaves/\"\n",
    "out_dir = \"classify-leaves/out/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231213d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= pd.read_csv(os.path.join(base_dir,\"train.csv\"))\n",
    "val_data = pd.read_csv(os.path.join(base_dir,\"test.csv\"))\n",
    "\n",
    "# 统计每个类别的数量\n",
    "label_counts = train_data['label'].value_counts()\n",
    "\n",
    "print(train_data.shape,'\\n')\n",
    "print(train_data.info(),'\\n')\n",
    "print(train_data.describe(), \"\\n\")\n",
    "print(train_data.head(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c217ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看前20张图片\n",
    "preview_image_paths = train_data['image'][:20]\n",
    "preview_image_labels = train_data['label'][:20]\n",
    "# 创建子图\n",
    "fig, axes = plt.subplots(4,5, figsize=(12, 8))  # 一行多列\n",
    "\n",
    "for i,(ax,img_path) in enumerate(zip(axes.flatten(),preview_image_paths)):\n",
    "    img = mpimg.imread(os.path.join(base_dir, img_path))  # 读取图片\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(preview_image_labels[i],y=-0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e646ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取所有唯一的类别（叶子种类）\n",
    "unique_labels = train_data[\"label\"].unique()\n",
    "\n",
    "# 创建 类别 → 索引 的映射\n",
    "label2idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "# 创建反向映射（id → label）\n",
    "idx2label = {v: k for k, v in label2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91465b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeaveDataset(Dataset):\n",
    "    def __init__(self, data_df, transform=None):\n",
    "        self.data = data_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(base_dir, self.data.iloc[idx,0])\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # 应用转换\n",
    "        \n",
    "        label_name = self.data.iloc[idx,1]\n",
    "        label = label2idx[label_name]  # 转换为整数索引\n",
    "\n",
    "        return image, label  # 返回 (图片, 标签)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aa6d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "\n",
    "# 定义数据转换\n",
    "transform = T.Compose([\n",
    "    # T.Resize((224, 224)),  # 调整图片大小\n",
    "    T.ToTensor(),  # 转为张量\n",
    "    # T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # 归一化\n",
    "])\n",
    "\n",
    "train_dataset = LeaveDataset(train_data,transform)\n",
    "\n",
    "# 计算拆分大小\n",
    "total_size = len(train_dataset)\n",
    "test_size = int(0.2 * total_size)  # 20% 作为测试集\n",
    "train_size = total_size - test_size  # 剩下的作为训练集\n",
    "\n",
    "# 随机拆分数据\n",
    "train_subset, test_subset = random_split(train_dataset, [train_size, test_size])\n",
    "\n",
    "# 重新创建 DataLoader\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print(\"总批次:\",len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1994500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 ResNet-18（可以换成 resnet34, resnet50, resnet101, resnet152）\n",
    "resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# 修改最终输出的类别\n",
    "num_classes = len(label_counts)  \n",
    "resnet.fc = torch.nn.Linear(resnet.fc.in_features, num_classes)\n",
    "\n",
    "# 设备类型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "print(resnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a806e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉熵损失（适用于分类问题）\n",
    "crossentropy = nn.CrossEntropyLoss()\n",
    "\n",
    "# 学习率，动量\n",
    "lr,momentum = 0.01,0.9\n",
    "\n",
    "# 优化器\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce01fed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单次训练\n",
    "def train():\n",
    "    resnet.train()\n",
    "\n",
    "    batch_nums = len(train_loader)  # 批次数\n",
    "    batch_size = train_loader.batch_size  # 批量大小\n",
    "    size = len(train_loader.dataset)  # 数据集大小\n",
    "    \n",
    "    train_loss,correct = 0.0, 0.0 # 统计损失和准确率\n",
    "\n",
    "    p = tqdm(train_loader, desc=\"Training\", unit=\"batch\")\n",
    "    \n",
    "    for X,y in p:\n",
    "        X,y = X.to(device),y.to(device)\n",
    "        pred = resnet(X)\n",
    "        loss = crossentropy(pred,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        p.set_postfix(loss=f\"{loss.item():>8f}\")  # 显示损失值\n",
    "        \n",
    "        train_loss+=loss.item() # 累计每个批次的平均损失\n",
    "        correct += (pred.argmax(1) == y).sum().item() # 计算正确预测的数量\n",
    "\n",
    "    train_loss /= batch_nums\n",
    "    correct /= size\n",
    "    print(f\"Train Accuracy: {(100*correct):>0.2f}%, Train Avg loss: {train_loss:>8f}\")\n",
    "\n",
    "    p.close()  # 清除进度条\n",
    "\n",
    "    return train_loss,correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6591b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证\n",
    "def test():\n",
    "    resnet.eval() # 评估模式\n",
    "    \n",
    "    batch_nums = len(test_loader)  # 批次数\n",
    "    batch_size = test_loader.batch_size  # 批量大小\n",
    "    size = len(test_loader.dataset)  # 数据集大小\n",
    "    \n",
    "    test_loss,correct = 0.0, 0.0 # 统计损失和准确率\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for X,y in test_loader:\n",
    "            X,y = X.to(device),y.to(device)\n",
    "            pred = resnet(X)\n",
    "            loss = crossentropy(pred,y)\n",
    "\n",
    "            test_loss+=loss.item() # 累计每个批次的平均损失\n",
    "            correct += (pred.argmax(1) == y).sum().item() # 计算正确预测的数量\n",
    "\n",
    "    test_loss /= batch_nums\n",
    "    correct /= size\n",
    "    print(f\"Test Accuracy: {(100*correct):>0.1f}%, Test Avg loss: {test_loss:>8f}\")\n",
    "    \n",
    "    return test_loss,correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa1fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练损失和准确率\n",
    "train_losses,train_accs = [],[]\n",
    "\n",
    "# 测试损失和准确率\n",
    "test_losses ,test_accs= [],[]\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "best_acc = 0.0  # 记录最佳准确率\n",
    "save_path = 'best_model.pth'  # 保存路径\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    train_loss,train_acc = train()\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    test_loss,test_acc = test()\n",
    "    test_losses.append(test_loss)\n",
    "    test_accs.append(test_acc)\n",
    "\n",
    "    # 保存最好的模型\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(resnet.state_dict(), save_path)  # 仅保存状态字典\n",
    "        print(f'New best model saved with accuracy: {best_acc:.4f}')\n",
    "\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad06c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制训练过程中的损失和准确率\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 绘制损失曲线\n",
    "axes[0].plot(range(1, epochs+1), train_losses, label='Train Loss', marker='o')\n",
    "axes[0].plot(range(1, epochs+1), test_losses, label='Test Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Test Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# 绘制准确率曲线\n",
    "axes[1].plot(range(1, epochs+1), [acc*100 for acc in train_accs], label='Train Accuracy', marker='o')\n",
    "axes[1].plot(range(1, epochs+1), [acc*100 for acc in test_accs], label='Test Accuracy', marker='s')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Training and Test Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'最佳测试准确率: {best_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a7e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新定义模型（确保架构一致）\n",
    "resnet = models.resnet18()\n",
    "resnet.fc = torch.nn.Linear(resnet.fc.in_features, num_classes)\n",
    "\n",
    "# 加载训练好的权重\n",
    "resnet.load_state_dict(torch.load(save_path,weights_only=True))\n",
    "\n",
    "# 切换到 eval 模式\n",
    "resnet.to(device)\n",
    "resnet.eval()\n",
    "print(\"模型已加载并设置为评估模式！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be8f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.eval()\n",
    "\n",
    "# 单张图片预测\n",
    "img_val_path = os.path.join(base_dir,val_data['image'][0])\n",
    "image_val = Image.open(img_val_path)\n",
    "image_val_tensor = transform(image_val).unsqueeze(0)  # 应用转换 升维\n",
    "\n",
    "# 预测\n",
    "with torch.no_grad():\n",
    "    image_val_tensor = image_val_tensor.to(device)\n",
    "    output = resnet(image_val_tensor)\n",
    "    probabilities = F.softmax(output, dim=1)  # 转换为概率\n",
    "    pred_class = torch.argmax(probabilities).item()\n",
    "\n",
    "print(torch.max(probabilities).item()*100,'%')\n",
    "print(idx2label[pred_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f10e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批量预测\n",
    "\n",
    "class LeaveValDataset(Dataset):\n",
    "    def __init__(self, data_df, transform=None):\n",
    "        self.data = data_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(base_dir, self.data.iloc[idx,0])\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # 应用转换\n",
    "        \n",
    "        return image\n",
    "\n",
    "val_dataset = LeaveValDataset(val_data,transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "print(\"val batch num:\",len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d24f0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs in tqdm(val_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = resnet(inputs)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "print(\"批量预测结果长度:\", len(all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8614f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = [idx2label[pred_id] for pred_id in all_preds] # 转换成label\n",
    "val_data['label'] = pred_labels\n",
    "val_data.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348cf6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
