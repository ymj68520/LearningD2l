{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353da4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 导入必要的库 ====================\n",
    "# %matplotlib inline: 在Jupyter中内嵌显示matplotlib图像\n",
    "%matplotlib inline\n",
    "\n",
    "# os: 操作系统接口，用于处理文件路径\n",
    "import os\n",
    "\n",
    "# torch: PyTorch深度学习框架\n",
    "import torch\n",
    "\n",
    "# torchvision: PyTorch的计算机视觉工具库，包含数据集、模型、图像变换等\n",
    "import torchvision\n",
    "\n",
    "# d2l: Dive into Deep Learning (动手学深度学习) 工具库\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1d0ac37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ../data/VOCtrainval_11-May-2012.tar from http://d2l-data.s3-accelerate.amazonaws.com/VOCtrainval_11-May-2012.tar...\n"
     ]
    }
   ],
   "source": [
    "# ==================== 下载VOC2012语义分割数据集 ====================\n",
    "# VOC2012是计算机视觉领域常用的语义分割数据集，大小约2GB\n",
    "# 语义分割：将图像中的每个像素都分类到特定类别（如人、车、猫等）\n",
    "\n",
    "# 在d2l的数据集Hub中注册VOC2012数据集的下载链接和校验码\n",
    "d2l.DATA_HUB['voc2012'] = (d2l.DATA_URL + 'VOCtrainval_11-May-2012.tar',\n",
    "                           '4e443f8a2eca6b1dac8a6c57641b67dd40621a49')\n",
    "\n",
    "# 下载并解压数据集到指定目录，返回数据集的路径\n",
    "# voc_dir 将包含数据集的根目录路径\n",
    "voc_dir = d2l.download_extract('voc2012', 'VOCdevkit/VOC2012')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78a44aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 读取VOC数据集的图像和标注 ====================\n",
    "def read_voc_images(voc_dir, is_train=True):\n",
    "    \"\"\"\n",
    "    读取所有VOC图像及其对应的语义分割标注\n",
    "    \n",
    "    参数:\n",
    "        voc_dir: VOC数据集的根目录路径\n",
    "        is_train: 布尔值，True读取训练集，False读取验证集\n",
    "    \n",
    "    返回:\n",
    "        features: 原始RGB图像列表\n",
    "        labels: 对应的语义分割标注图像列表（每个像素用不同颜色表示不同类别）\n",
    "    \"\"\"\n",
    "    # 根据is_train参数确定读取train.txt还是val.txt\n",
    "    # 这些txt文件包含了图像文件名列表\n",
    "    txt_fname = os.path.join(voc_dir, 'ImageSets', 'Segmentation',\n",
    "                             'train.txt' if is_train else 'val.txt')\n",
    "    \n",
    "    # 设置读取模式为RGB彩色图像\n",
    "    mode = torchvision.io.image.ImageReadMode.RGB\n",
    "    \n",
    "    # 打开txt文件并读取所有图像文件名\n",
    "    with open(txt_fname, 'r') as f:\n",
    "        images = f.read().split()  # 将文件内容按空白字符分割成列表\n",
    "    \n",
    "    # 初始化特征(原图)和标签(分割标注)列表\n",
    "    features, labels = [], []\n",
    "    \n",
    "    # 遍历所有图像文件名\n",
    "    for i, fname in enumerate(images):\n",
    "        # 读取原始RGB图像（JPEGImages目录下的.jpg文件）\n",
    "        features.append(torchvision.io.read_image(os.path.join(\n",
    "            voc_dir, 'JPEGImages', f'{fname}.jpg')))\n",
    "        \n",
    "        # 读取对应的语义分割标注图像（SegmentationClass目录下的.png文件）\n",
    "        # 标注图像中，不同颜色代表不同的物体类别\n",
    "        labels.append(torchvision.io.read_image(os.path.join(\n",
    "            voc_dir, 'SegmentationClass' ,f'{fname}.png'), mode))\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "# 读取训练集的图像和标注\n",
    "train_features, train_labels = read_voc_images(voc_dir, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f59309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 可视化原始图像和标注 ====================\n",
    "# 显示前5张图像及其对应的分割标注\n",
    "\n",
    "n = 5  # 要显示的图像数量\n",
    "\n",
    "# 将原始图像和标注图像合并到一个列表中\n",
    "# train_features[0:n] 是前5张原始图像\n",
    "# train_labels[0:n] 是前5张标注图像\n",
    "imgs = train_features[0:n] + train_labels[0:n]\n",
    "\n",
    "# 调整图像张量的维度顺序\n",
    "# 从 (C, H, W) 转换为 (H, W, C)，因为显示函数需要这种格式\n",
    "# C=通道数(RGB=3), H=高度, W=宽度\n",
    "imgs = [img.permute(1, 2, 0) for img in imgs]\n",
    "\n",
    "# 显示图像：2行，每行n张\n",
    "# 第一行显示原始图像，第二行显示对应的分割标注\n",
    "d2l.show_images(imgs, 2, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c86e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 定义VOC数据集的类别和颜色映射 ====================\n",
    "\n",
    "# VOC_COLORMAP: RGB颜色映射表，每种颜色对应一个物体类别\n",
    "# 例如：[0, 0, 0]是黑色代表背景，[128, 0, 0]是深红色代表飞机\n",
    "# 这些颜色在标注图像中用来区分不同的物体类别\n",
    "VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n",
    "                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n",
    "                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n",
    "                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n",
    "                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n",
    "                [0, 64, 128]]\n",
    "\n",
    "# VOC_CLASSES: 21个类别的名称，与上面的颜色一一对应\n",
    "# 索引0是背景，索引1是飞机，索引2是自行车，等等\n",
    "VOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
    "               'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "               'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8661839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 构建颜色到类别索引的映射 ====================\n",
    "\n",
    "def voc_colormap2label():\n",
    "    \"\"\"\n",
    "    构建从RGB颜色值到类别索引的映射\n",
    "    \n",
    "    为什么需要这个映射？\n",
    "    - 标注图像中每个像素都是RGB颜色值（如[128, 0, 0]）\n",
    "    - 但神经网络需要的是类别索引（如0, 1, 2...）\n",
    "    - 这个函数创建一个查找表，快速将RGB转换为类别索引\n",
    "    \n",
    "    返回:\n",
    "        colormap2label: 一维张量，长度为256^3（所有可能的RGB组合）\n",
    "                       索引是RGB值的整数表示，值是对应的类别索引\n",
    "    \"\"\"\n",
    "    # 创建一个大小为256^3的零张量（可以表示所有RGB组合）\n",
    "    colormap2label = torch.zeros(256**3, dtype=torch.long)\n",
    "    \n",
    "    # 遍历所有预定义的颜色\n",
    "    for i, colormap in enumerate(VOC_COLORMAP):\n",
    "        # 将RGB三通道值转换为一个唯一的整数索引\n",
    "        # 公式: (R * 256 + G) * 256 + B\n",
    "        # 例如：[128, 0, 0] -> (128*256 + 0)*256 + 0 = 8388608\n",
    "        colormap2label[(colormap[0] * 256 + colormap[1]) * 256 + colormap[2]] = i\n",
    "    \n",
    "    return colormap2label\n",
    "\n",
    "\n",
    "def voc_label_indices(colormap, colormap2label):\n",
    "    \"\"\"\n",
    "    将VOC标注图像中的RGB颜色值转换为类别索引\n",
    "    \n",
    "    参数:\n",
    "        colormap: 标注图像张量，形状为 (3, H, W)\n",
    "        colormap2label: RGB到类别索引的映射表\n",
    "    \n",
    "    返回:\n",
    "        类别索引张量，形状为 (H, W)，每个元素是0-20之间的类别索引\n",
    "    \"\"\"\n",
    "    # 将张量从 (C, H, W) 转换为 (H, W, C)，并转换为numpy数组\n",
    "    colormap = colormap.permute(1, 2, 0).numpy().astype('int32')\n",
    "    \n",
    "    # 将每个像素的RGB值转换为单一整数索引\n",
    "    # 对于图像中的每个像素，计算其RGB对应的整数值\n",
    "    idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256\n",
    "           + colormap[:, :, 2])\n",
    "    \n",
    "    # 使用映射表将整数索引转换为类别索引\n",
    "    return colormap2label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4db669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 测试颜色到类别索引的转换 ====================\n",
    "# 将第一张标注图像转换为类别索引矩阵\n",
    "y = voc_label_indices(train_labels[0], voc_colormap2label())\n",
    "\n",
    "# 打印图像中一小块区域(10x15像素)的类别索引\n",
    "# 这样可以看到某个区域内各像素的类别编号\n",
    "print(y[105:115, 125:140])  # 显示从第105-114行，第125-139列的类别索引\n",
    "\n",
    "# 打印索引1对应的类别名称（应该是'aeroplane'飞机）\n",
    "print(VOC_CLASSES[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdceb2d4",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "# ==================== 随机裁剪数据增强 ====================\n",
    "\n",
    "def voc_rand_crop(feature, label, height, width):\n",
    "    \"\"\"\n",
    "    对图像和标注进行相同位置的随机裁剪\n",
    "    \n",
    "    为什么需要随机裁剪？\n",
    "    1. 数据增强：增加训练样本的多样性\n",
    "    2. 统一尺寸：神经网络需要固定大小的输入\n",
    "    3. 重要：图像和标注必须裁剪相同位置，保证对应关系\n",
    "    \n",
    "    参数:\n",
    "        feature: 原始图像\n",
    "        label: 标注图像\n",
    "        height, width: 裁剪后的目标高度和宽度\n",
    "    \n",
    "    返回:\n",
    "        裁剪后的图像和标注\n",
    "    \"\"\"\n",
    "    # 随机获取裁剪区域的参数（左上角坐标、高度、宽度）\n",
    "    rect = torchvision.transforms.RandomCrop.get_params(\n",
    "        feature, (height, width))\n",
    "    \n",
    "    # 对原始图像进行裁剪\n",
    "    feature = torchvision.transforms.functional.crop(feature, *rect)\n",
    "    \n",
    "    # 对标注图像进行相同位置的裁剪（确保像素级对应）\n",
    "    label = torchvision.transforms.functional.crop(label, *rect)\n",
    "    \n",
    "    return feature, label\n",
    "\n",
    "\n",
    "# ==================== 可视化随机裁剪效果 ====================\n",
    "imgs = []\n",
    "\n",
    "# 对同一张图像进行n次随机裁剪，展示数据增强的效果\n",
    "for _ in range(n):\n",
    "    # 每次裁剪得到一对(图像, 标注)\n",
    "    imgs += voc_rand_crop(\n",
    "        train_features[0], train_labels[0], 200, 300)\n",
    "\n",
    "# 调整维度以便显示\n",
    "imgs = [img.permute(1, 2, 0) for img in imgs]\n",
    "\n",
    "# 显示裁剪结果：第一行显示n个裁剪后的图像，第二行显示对应的标注\n",
    "# imgs[::2] 是所有偶数索引（原始图像）\n",
    "# imgs[1::2] 是所有奇数索引（标注图像）\n",
    "d2l.show_images(imgs[::2] + imgs[1::2], 2, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180d7ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 自定义VOC数据集类 ====================\n",
    "\n",
    "class VOCSegDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    用于加载VOC语义分割数据集的自定义Dataset类\n",
    "    \n",
    "    这个类封装了数据加载、预处理的全部流程：\n",
    "    1. 读取图像\n",
    "    2. 过滤太小的图像\n",
    "    3. 归一化图像\n",
    "    4. 在训练时随机裁剪\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, is_train, crop_size, voc_dir):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        \n",
    "        参数:\n",
    "            is_train: 是否为训练集\n",
    "            crop_size: 裁剪尺寸(height, width)\n",
    "            voc_dir: VOC数据集目录\n",
    "        \"\"\"\n",
    "        # 图像归一化：使用ImageNet的均值和标准差\n",
    "        # 这是计算机视觉中的常见做法，有助于模型收敛\n",
    "        # mean: 每个通道(RGB)的均值\n",
    "        # std: 每个通道的标准差\n",
    "        self.transform = torchvision.transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        self.crop_size = crop_size\n",
    "        \n",
    "        # 读取所有图像和标注\n",
    "        features, labels = read_voc_images(voc_dir, is_train=is_train)\n",
    "        \n",
    "        # 过滤掉尺寸小于crop_size的图像，然后归一化\n",
    "        # self.filter() 只保留足够大的图像\n",
    "        # self.normalize_image() 对每张图像进行归一化\n",
    "        self.features = [self.normalize_image(feature)\n",
    "                         for feature in self.filter(features)]\n",
    "        \n",
    "        # 同样过滤标注图像\n",
    "        self.labels = self.filter(labels)\n",
    "        \n",
    "        # 创建颜色到类别索引的映射表\n",
    "        self.colormap2label = voc_colormap2label()\n",
    "        \n",
    "        # 打印读取的样本数量\n",
    "        print('read ' + str(len(self.features)) + ' examples')\n",
    "\n",
    "    def normalize_image(self, img):\n",
    "        \"\"\"\n",
    "        归一化图像\n",
    "        \n",
    "        步骤:\n",
    "        1. 将像素值从[0, 255]缩放到[0, 1]\n",
    "        2. 使用ImageNet的均值和标准差进行标准化\n",
    "        \"\"\"\n",
    "        return self.transform(img.float() / 255)\n",
    "\n",
    "    def filter(self, imgs):\n",
    "        \"\"\"\n",
    "        过滤掉太小的图像\n",
    "        \n",
    "        只保留高度>=crop_size[0] 且 宽度>=crop_size[1] 的图像\n",
    "        因为太小的图像无法裁剪出所需尺寸\n",
    "        \"\"\"\n",
    "        return [img for img in imgs if (\n",
    "            img.shape[1] >= self.crop_size[0] and\n",
    "            img.shape[2] >= self.crop_size[1])]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取第idx个样本\n",
    "        \n",
    "        这是Dataset类必须实现的方法\n",
    "        每次DataLoader取数据时都会调用这个方法\n",
    "        \n",
    "        返回:\n",
    "            feature: 裁剪并归一化后的图像\n",
    "            label: 对应的类别索引标注（已转换为类别索引）\n",
    "        \"\"\"\n",
    "        # 随机裁剪图像和标注到指定尺寸\n",
    "        feature, label = voc_rand_crop(self.features[idx], self.labels[idx],\n",
    "                                       *self.crop_size)\n",
    "        \n",
    "        # 将标注从RGB颜色转换为类别索引\n",
    "        return (feature, voc_label_indices(label, self.colormap2label))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回数据集的大小\n",
    "        \n",
    "        这是Dataset类必须实现的方法\n",
    "        \"\"\"\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb18a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 创建训练集和测试集 ====================\n",
    "\n",
    "# 设置裁剪尺寸：高度320像素，宽度480像素\n",
    "crop_size = (320, 480)\n",
    "\n",
    "# 创建训练集数据集对象\n",
    "voc_train = VOCSegDataset(True, crop_size, voc_dir)\n",
    "\n",
    "# 创建测试集（验证集）数据集对象\n",
    "voc_test = VOCSegDataset(False, crop_size, voc_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa33771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 创建数据加载器并测试 ====================\n",
    "\n",
    "# 设置批次大小：每次训练使用64个样本\n",
    "batch_size = 64\n",
    "\n",
    "# 创建数据加载器（DataLoader）\n",
    "# DataLoader的作用：\n",
    "# 1. 自动分批次加载数据\n",
    "# 2. 支持多进程加载，提高效率\n",
    "# 3. 支持数据打乱（shuffle）\n",
    "train_iter = torch.utils.data.DataLoader(\n",
    "    voc_train,                                    # 数据集对象\n",
    "    batch_size,                                   # 批次大小\n",
    "    shuffle=True,                                 # 打乱数据顺序（训练时很重要）\n",
    "    drop_last=True,                               # 丢弃最后不足一个batch的数据\n",
    "    num_workers=d2l.get_dataloader_workers())     # 多进程加载数据的进程数\n",
    "\n",
    "# 测试数据加载器：获取一个批次的数据并查看形状\n",
    "for X, Y in train_iter:\n",
    "    print(X.shape)  # 图像形状: (batch_size, 3, 320, 480)\n",
    "                     # 3是RGB三通道\n",
    "    print(Y.shape)  # 标注形状: (batch_size, 320, 480)\n",
    "                     # 每个元素是0-20之间的类别索引\n",
    "    break            # 只看第一个批次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d3ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 封装数据加载函数 ====================\n",
    "\n",
    "def load_data_voc(batch_size, crop_size):\n",
    "    \"\"\"\n",
    "    加载VOC语义分割数据集的便捷函数\n",
    "    \n",
    "    这个函数封装了整个数据加载流程，便于在其他地方调用\n",
    "    \n",
    "    参数:\n",
    "        batch_size: 批次大小\n",
    "        crop_size: 裁剪尺寸(height, width)\n",
    "    \n",
    "    返回:\n",
    "        train_iter: 训练集数据迭代器\n",
    "        test_iter: 测试集数据迭代器\n",
    "    \"\"\"\n",
    "    # 下载并获取VOC数据集路径\n",
    "    voc_dir = d2l.download_extract('voc2012', os.path.join(\n",
    "        'VOCdevkit', 'VOC2012'))\n",
    "    \n",
    "    # 获取合适的worker数量（用于多进程数据加载）\n",
    "    num_workers = d2l.get_dataloader_workers()\n",
    "    \n",
    "    # 创建训练集数据加载器\n",
    "    train_iter = torch.utils.data.DataLoader(\n",
    "        VOCSegDataset(True, crop_size, voc_dir),  # 训练集\n",
    "        batch_size,\n",
    "        shuffle=True,                              # 训练时打乱数据\n",
    "        drop_last=True,                            # 丢弃不完整的批次\n",
    "        num_workers=num_workers)\n",
    "    \n",
    "    # 创建测试集数据加载器\n",
    "    test_iter = torch.utils.data.DataLoader(\n",
    "        VOCSegDataset(False, crop_size, voc_dir), # 测试集\n",
    "        batch_size,\n",
    "        drop_last=True,                            # 丢弃不完整的批次\n",
    "        num_workers=num_workers)                   # 测试时不需要打乱\n",
    "    \n",
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e82430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
