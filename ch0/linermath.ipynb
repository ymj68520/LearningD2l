{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6dc469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98923aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  8, 12, 16],\n",
       "        [ 1,  5,  9, 13, 17],\n",
       "        [ 2,  6, 10, 14, 18],\n",
       "        [ 3,  7, 11, 15, 19]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20).reshape(5,4)\n",
    "A.T # Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80776a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [2, 0, 4],\n",
      "        [3, 4, 5]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  6, 12])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.tensor([[1,2,3],[2,0,4],[3,4,5]])\n",
    "print(B)\n",
    "B == B.T  # Check symmetry\n",
    "A = B.clone()\n",
    "A.sum(axis=1)  # Sum all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf1aa667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6667)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.6667)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(B.float().mean() ) # Mean of all elements\n",
    "C = B.sum()/B.numel()  # Alternative way to compute mean\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ad9d967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6],\n",
      "        [ 6],\n",
      "        [12]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1667, 0.3333, 0.5000],\n",
       "        [0.3333, 0.0000, 0.6667],\n",
       "        [0.2500, 0.3333, 0.4167]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_B = B.sum(axis=1, keepdim=True)\n",
    "print(sum_B)\n",
    "B / sum_B  # Normalize rows to sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a41d41e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3],\n",
       "        [ 3,  2,  7],\n",
       "        [ 6,  6, 12]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.cumsum(axis=0) # Cumulative sum along rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee95e1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1.]),\n",
       " tensor([[[-0.3854, -1.2704,  1.3633],\n",
       "          [-0.7043, -0.2405, -0.5592]]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear algebra operations\n",
    "x = torch.ones(3, dtype=torch.float32)\n",
    "y = torch.randn((1,2,3), dtype=torch.float32)\n",
    "x, y, # torch.dot(x, y) # Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e35f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3]), torch.Size([3]), tensor([ 6.,  6., 12.]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape, x.shape, torch.mv(B.float(), x)  # Matrix-vector product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce0317c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14., 14., 26.],\n",
       "        [14., 20., 26.],\n",
       "        [26., 26., 50.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(A.float(), B.float())  # Matrix-matrix product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a711b702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.ones(4, dtype=torch.float32))  # Vector norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a420e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.1652)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(A.float())  # Frobenius norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5439927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(A).sum()  # Sum of absolute values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
