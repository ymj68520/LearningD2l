{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# YOLOv3 完整实现\n",
                "\n",
                "## 目录\n",
                "1. 导入库和数据准备\n",
                "2. Darknet骨干网络\n",
                "3. YOLOv3检测头\n",
                "4. 损失函数\n",
                "5. 完整模型\n",
                "6. 训练和推理"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# 第1部分：导入必要的库\n",
                "# ============================================================\n",
                "\n",
                "# PyTorch核心库 - 深度学习的基础框架\n",
                "import torch\n",
                "\n",
                "# nn模块包含神经网络的各种层(卷积、全连接等)\n",
                "import torch.nn as nn\n",
                "\n",
                "# F模块包含函数式API(激活函数、损失函数等)\n",
                "import torch.nn.functional as F\n",
                "\n",
                "# 数据加载工具\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "\n",
                "# torchvision是PyTorch的计算机视觉工具库\n",
                "import torchvision\n",
                "from torchvision import transforms\n",
                "\n",
                "# 目标检测专用操作：非极大值抑制(NMS)\n",
                "from torchvision.ops import nms\n",
                "\n",
                "# 数值计算库\n",
                "import numpy as np\n",
                "\n",
                "# 绘图库\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.patches as patches\n",
                "\n",
                "# 检测并设置计算设备(GPU优先)\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"使用设备: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 数据集准备\n",
                "\n",
                "将CIFAR-10分类数据集适配为目标检测格式。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CIFAR-10目标检测数据集适配器\n",
                "# 将分类数据集转换为检测格式(为每张图创建边界框)\n",
                "# ============================================================\n",
                "\n",
                "class CIFAR10Detection(Dataset):\n",
                "    \"\"\"CIFAR-10检测数据集包装类\n",
                "    \n",
                "    CIFAR-10原本是分类数据集，这里为每张图创建覆盖整图的边界框\n",
                "    用于演示YOLOv3的工作流程\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, root, train=True, transform=None, img_size=416):\n",
                "        \"\"\"初始化数据集\n",
                "        \n",
                "        Args:\n",
                "            root: 数据集根目录\n",
                "            train: True为训练集，False为测试集\n",
                "            transform: 图像变换操作\n",
                "            img_size: YOLOv3输入图像大小(通常为416或608)\n",
                "        \"\"\"\n",
                "        # 加载CIFAR-10数据集(自动下载)\n",
                "        self.cifar10 = torchvision.datasets.CIFAR10(\n",
                "            root=root, \n",
                "            train=train, \n",
                "            download=True, \n",
                "            transform=None  # 先不变换，后面手动处理\n",
                "        )\n",
                "        self.transform = transform\n",
                "        self.img_size = img_size\n",
                "        # 10个类别名称\n",
                "        self.classes = self.cifar10.classes\n",
                "        self.num_classes = len(self.classes)\n",
                "    \n",
                "    def __len__(self):\n",
                "        \"\"\"返回数据集大小\"\"\"\n",
                "        return len(self.cifar10)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        \"\"\"获取一个样本\n",
                "        \n",
                "        Returns:\n",
                "            img: 图像张量 [3, img_size, img_size]\n",
                "            target: 包含boxes和labels的字典\n",
                "        \"\"\"\n",
                "        # 获取图像和类别标签\n",
                "        img, label = self.cifar10[idx]\n",
                "        \n",
                "        # 将PIL图像调整到YOLOv3输入尺寸\n",
                "        img = img.resize((self.img_size, self.img_size))\n",
                "        \n",
                "        if self.transform:\n",
                "            img = self.transform(img)\n",
                "        \n",
                "        # YOLO格式边界框: [x_center, y_center, width, height] 归一化到[0,1]\n",
                "        # 由于整个图像就是目标，边界框覆盖整图\n",
                "        boxes = torch.tensor([[0.5, 0.5, 1.0, 1.0]], dtype=torch.float32)\n",
                "        \n",
                "        # 类别标签\n",
                "        labels = torch.tensor([label], dtype=torch.int64)\n",
                "        \n",
                "        # 构建目标字典\n",
                "        target = {\n",
                "            \"boxes\": boxes,      # YOLO格式边界框 [x_c, y_c, w, h]\n",
                "            \"labels\": labels     # 类别标签(0-9)\n",
                "        }\n",
                "        \n",
                "        return img, target\n",
                "\n",
                "\n",
                "# 定义图像变换\n",
                "transform = transforms.Compose([\n",
                "    transforms.ToTensor(),  # [0,255] -> [0,1]\n",
                "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
                "                        std=[0.229, 0.224, 0.225])  # ImageNet标准化\n",
                "])\n",
                "\n",
                "# 创建数据集\n",
                "train_dataset = CIFAR10Detection(root='./data', train=True, transform=transform, img_size=416)\n",
                "test_dataset = CIFAR10Detection(root='./data', train=False, transform=transform, img_size=416)\n",
                "\n",
                "# 创建数据加载器\n",
                "train_loader = DataLoader(\n",
                "    train_dataset, \n",
                "    batch_size=4, \n",
                "    shuffle=True, \n",
                "    collate_fn=lambda x: tuple(zip(*x))\n",
                ")\n",
                "test_loader = DataLoader(\n",
                "    test_dataset, \n",
                "    batch_size=4, \n",
                "    shuffle=False, \n",
                "    collate_fn=lambda x: tuple(zip(*x))\n",
                ")\n",
                "\n",
                "print(f\"训练集大小: {len(train_dataset)}\")\n",
                "print(f\"测试集大小: {len(test_dataset)}\")\n",
                "print(f\"类别: {train_dataset.classes}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Darknet骨干网络\n",
                "\n",
                "YOLOv3使用Darknet-53作为骨干网络，具有残差连接结构。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# Darknet基础模块\n",
                "# ============================================================\n",
                "\n",
                "class ConvBNLeaky(nn.Module):\n",
                "    \"\"\"卷积 + BatchNorm + LeakyReLU\n",
                "    \n",
                "    YOLOv3的基本构建单元，几乎所有卷积都使用这个组合\n",
                "    LeakyReLU(0.1)是YOLO系列的标准激活函数\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
                "        \"\"\"初始化\n",
                "        \n",
                "        Args:\n",
                "            in_channels: 输入通道数\n",
                "            out_channels: 输出通道数\n",
                "            kernel_size: 卷积核大小\n",
                "            stride: 步长\n",
                "            padding: 填充\n",
                "        \"\"\"\n",
                "        super(ConvBNLeaky, self).__init__()\n",
                "        \n",
                "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, \n",
                "                              stride, padding, bias=False)\n",
                "        self.bn = nn.BatchNorm2d(out_channels)\n",
                "        self.leaky = nn.LeakyReLU(0.1, inplace=True)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        return self.leaky(self.bn(self.conv(x)))\n",
                "\n",
                "\n",
                "class DarknetResidualBlock(nn.Module):\n",
                "    \"\"\"Darknet残差块\n",
                "    \n",
                "    结构: 1x1卷积(降维) -> 3x3卷积(特征提取) -> 残差连接\n",
                "    与ResNet不同，这里不需要下采样shortcut\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, in_channels):\n",
                "        \"\"\"初始化\n",
                "        \n",
                "        Args:\n",
                "            in_channels: 输入通道数(也是输出通道数)\n",
                "        \"\"\"\n",
                "        super(DarknetResidualBlock, self).__init__()\n",
                "        \n",
                "        reduced_channels = in_channels // 2  # 中间层通道减半\n",
                "        \n",
                "        # 1x1卷积降维\n",
                "        self.conv1 = ConvBNLeaky(in_channels, reduced_channels, \n",
                "                                  kernel_size=1, stride=1, padding=0)\n",
                "        # 3x3卷积提取特征\n",
                "        self.conv2 = ConvBNLeaky(reduced_channels, in_channels, \n",
                "                                  kernel_size=3, stride=1, padding=1)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        residual = x  # 保存输入用于残差连接\n",
                "        out = self.conv1(x)\n",
                "        out = self.conv2(out)\n",
                "        return out + residual  # 残差连接\n",
                "\n",
                "\n",
                "print(\"Darknet基础模块定义完成\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# Darknet-53骨干网络\n",
                "# ============================================================\n",
                "\n",
                "class Darknet53(nn.Module):\n",
                "    \"\"\"Darknet-53骨干网络\n",
                "    \n",
                "    YOLOv3的特征提取网络\n",
                "    命名53是因为有53个卷积层(1 + 2 + 8 + 8 + 8 + 4 + 8 + 8 + 4 = 53)\n",
                "    \n",
                "    特点:\n",
                "    1. 使用残差连接\n",
                "    2. 不使用池化层，用stride=2的卷积下采样\n",
                "    3. 输出三个尺度的特征图用于多尺度检测\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        super(Darknet53, self).__init__()\n",
                "        \n",
                "        # 初始卷积: 416x416x3 -> 416x416x32\n",
                "        self.conv1 = ConvBNLeaky(3, 32, kernel_size=3, stride=1, padding=1)\n",
                "        \n",
                "        # 下采样 + 残差块组\n",
                "        # Stage1: 416->208, 32->64通道, 1个残差块\n",
                "        self.stage1 = self._make_stage(32, 64, num_blocks=1)\n",
                "        \n",
                "        # Stage2: 208->104, 64->128通道, 2个残差块\n",
                "        self.stage2 = self._make_stage(64, 128, num_blocks=2)\n",
                "        \n",
                "        # Stage3: 104->52, 128->256通道, 8个残差块 (输出尺度3)\n",
                "        self.stage3 = self._make_stage(128, 256, num_blocks=8)\n",
                "        \n",
                "        # Stage4: 52->26, 256->512通道, 8个残差块 (输出尺度2)\n",
                "        self.stage4 = self._make_stage(256, 512, num_blocks=8)\n",
                "        \n",
                "        # Stage5: 26->13, 512->1024通道, 4个残差块 (输出尺度1)\n",
                "        self.stage5 = self._make_stage(512, 1024, num_blocks=4)\n",
                "    \n",
                "    def _make_stage(self, in_channels, out_channels, num_blocks):\n",
                "        \"\"\"构建一个stage\n",
                "        \n",
                "        每个stage包含:\n",
                "        1. 一个stride=2的下采样卷积\n",
                "        2. 多个残差块\n",
                "        \n",
                "        Args:\n",
                "            in_channels: 输入通道数\n",
                "            out_channels: 输出通道数\n",
                "            num_blocks: 残差块数量\n",
                "        \"\"\"\n",
                "        layers = []\n",
                "        # 下采样卷积: stride=2, 尺寸减半\n",
                "        layers.append(ConvBNLeaky(in_channels, out_channels, \n",
                "                                   kernel_size=3, stride=2, padding=1))\n",
                "        # 添加残差块\n",
                "        for _ in range(num_blocks):\n",
                "            layers.append(DarknetResidualBlock(out_channels))\n",
                "        return nn.Sequential(*layers)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        \"\"\"前向传播\n",
                "        \n",
                "        Args:\n",
                "            x: 输入图像 [B, 3, 416, 416]\n",
                "        Returns:\n",
                "            三个尺度的特征图:\n",
                "            - scale1: [B, 1024, 13, 13]  小目标\n",
                "            - scale2: [B, 512, 26, 26]   中等目标\n",
                "            - scale3: [B, 256, 52, 52]   大目标\n",
                "        \"\"\"\n",
                "        x = self.conv1(x)      # [B, 32, 416, 416]\n",
                "        x = self.stage1(x)     # [B, 64, 208, 208]\n",
                "        x = self.stage2(x)     # [B, 128, 104, 104]\n",
                "        \n",
                "        # 保存用于多尺度融合的特征\n",
                "        scale3 = self.stage3(x)   # [B, 256, 52, 52]\n",
                "        scale2 = self.stage4(scale3)  # [B, 512, 26, 26]\n",
                "        scale1 = self.stage5(scale2)  # [B, 1024, 13, 13]\n",
                "        \n",
                "        return scale1, scale2, scale3\n",
                "\n",
                "\n",
                "print(\"Darknet-53骨干网络定义完成\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. YOLOv3检测头\n",
                "\n",
                "YOLOv3在三个尺度上进行检测，每个尺度有独立的检测头。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# YOLOv3检测头\n",
                "# ============================================================\n",
                "\n",
                "class YOLODetectionHead(nn.Module):\n",
                "    \"\"\"YOLOv3检测头\n",
                "    \n",
                "    对每个尺度的特征图进行目标检测\n",
                "    每个grid cell预测3个anchor box\n",
                "    每个anchor box预测: 4个坐标 + 1个置信度 + num_classes个类别概率\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, in_channels, num_classes=10, num_anchors=3):\n",
                "        \"\"\"初始化\n",
                "        \n",
                "        Args:\n",
                "            in_channels: 输入通道数\n",
                "            num_classes: 类别数(CIFAR-10有10类)\n",
                "            num_anchors: 每个位置的anchor数量(YOLOv3每个尺度3个)\n",
                "        \"\"\"\n",
                "        super(YOLODetectionHead, self).__init__()\n",
                "        \n",
                "        self.num_classes = num_classes\n",
                "        self.num_anchors = num_anchors\n",
                "        # 每个anchor的输出: 4(坐标) + 1(置信度) + num_classes\n",
                "        self.num_outputs = num_anchors * (5 + num_classes)\n",
                "        \n",
                "        # 5个卷积层提取特征\n",
                "        mid_channels = in_channels // 2\n",
                "        self.conv1 = ConvBNLeaky(in_channels, mid_channels, 1, 1, 0)\n",
                "        self.conv2 = ConvBNLeaky(mid_channels, in_channels, 3, 1, 1)\n",
                "        self.conv3 = ConvBNLeaky(in_channels, mid_channels, 1, 1, 0)\n",
                "        self.conv4 = ConvBNLeaky(mid_channels, in_channels, 3, 1, 1)\n",
                "        self.conv5 = ConvBNLeaky(in_channels, mid_channels, 1, 1, 0)\n",
                "        \n",
                "        # 输出分支\n",
                "        self.conv6 = ConvBNLeaky(mid_channels, in_channels, 3, 1, 1)\n",
                "        # 最终输出层，不使用BN和激活函数\n",
                "        self.output = nn.Conv2d(in_channels, self.num_outputs, 1, 1, 0)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        \"\"\"前向传播\n",
                "        \n",
                "        Args:\n",
                "            x: 特征图 [B, C, H, W]\n",
                "        Returns:\n",
                "            output: 检测输出 [B, num_anchors*(5+num_classes), H, W]\n",
                "            route: 用于上采样融合的特征 [B, C/2, H, W]\n",
                "        \"\"\"\n",
                "        x = self.conv1(x)\n",
                "        x = self.conv2(x)\n",
                "        x = self.conv3(x)\n",
                "        x = self.conv4(x)\n",
                "        route = self.conv5(x)  # 保存用于上采样\n",
                "        \n",
                "        x = self.conv6(route)\n",
                "        output = self.output(x)\n",
                "        \n",
                "        return output, route\n",
                "\n",
                "\n",
                "class YOLOUpsample(nn.Module):\n",
                "    \"\"\"上采样模块\n",
                "    \n",
                "    将特征图上采样后与更高分辨率的特征concat\n",
                "    用于特征金字塔融合\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, in_channels):\n",
                "        super(YOLOUpsample, self).__init__()\n",
                "        # 1x1卷积降维\n",
                "        self.conv = ConvBNLeaky(in_channels, in_channels // 2, 1, 1, 0)\n",
                "        # 最近邻上采样\n",
                "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
                "    \n",
                "    def forward(self, x, route):\n",
                "        \"\"\"前向传播\n",
                "        \n",
                "        Args:\n",
                "            x: 低分辨率特征图\n",
                "            route: 高分辨率特征图(来自骨干网络)\n",
                "        Returns:\n",
                "            融合后的特征图\n",
                "        \"\"\"\n",
                "        x = self.conv(x)\n",
                "        x = self.upsample(x)\n",
                "        # 在通道维度上拼接\n",
                "        x = torch.cat([x, route], dim=1)\n",
                "        return x\n",
                "\n",
                "\n",
                "print(\"YOLOv3检测头定义完成\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. 损失函数\n",
                "\n",
                "YOLOv3的损失函数包括坐标损失、置信度损失和分类损失。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# YOLOv3损失函数\n",
                "# ============================================================\n",
                "\n",
                "class YOLOLoss(nn.Module):\n",
                "    \"\"\"YOLOv3损失函数\n",
                "    \n",
                "    损失组成:\n",
                "    1. 坐标损失: 预测框和真实框的位置误差\n",
                "    2. 置信度损失: 有目标和无目标的置信度误差\n",
                "    3. 分类损失: 类别预测误差\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, num_classes=10, anchors=None, img_size=416):\n",
                "        \"\"\"初始化\n",
                "        \n",
                "        Args:\n",
                "            num_classes: 类别数\n",
                "            anchors: anchor尺寸列表\n",
                "            img_size: 输入图像大小\n",
                "        \"\"\"\n",
                "        super(YOLOLoss, self).__init__()\n",
                "        \n",
                "        self.num_classes = num_classes\n",
                "        self.img_size = img_size\n",
                "        \n",
                "        # YOLOv3默认anchors (宽, 高)\n",
                "        # 三个尺度，每个尺度3个anchor\n",
                "        if anchors is None:\n",
                "            self.anchors = [\n",
                "                [(116, 90), (156, 198), (373, 326)],  # 13x13尺度,大目标\n",
                "                [(30, 61), (62, 45), (59, 119)],       # 26x26尺度,中等目标\n",
                "                [(10, 13), (16, 30), (33, 23)]         # 52x52尺度,小目标\n",
                "            ]\n",
                "        else:\n",
                "            self.anchors = anchors\n",
                "        \n",
                "        # 损失权重\n",
                "        self.lambda_coord = 5.0    # 坐标损失权重\n",
                "        self.lambda_noobj = 0.5    # 无目标置信度损失权重\n",
                "        \n",
                "        # 损失函数\n",
                "        self.mse_loss = nn.MSELoss(reduction='sum')  # 坐标损失\n",
                "        self.bce_loss = nn.BCEWithLogitsLoss(reduction='sum')  # 置信度和分类损失\n",
                "    \n",
                "    def forward(self, predictions, targets, scale_idx):\n",
                "        \"\"\"计算损失\n",
                "        \n",
                "        Args:\n",
                "            predictions: 模型预测 [B, num_anchors*(5+C), H, W]\n",
                "            targets: 真实标注\n",
                "            scale_idx: 当前尺度索引(0,1,2)\n",
                "        Returns:\n",
                "            总损失\n",
                "        \"\"\"\n",
                "        batch_size = predictions.size(0)\n",
                "        grid_size = predictions.size(2)\n",
                "        num_anchors = len(self.anchors[scale_idx])\n",
                "        \n",
                "        # 重塑预测张量: [B, 3, 5+C, H, W] -> [B, 3, H, W, 5+C]\n",
                "        predictions = predictions.view(\n",
                "            batch_size, num_anchors, 5 + self.num_classes, \n",
                "            grid_size, grid_size\n",
                "        ).permute(0, 1, 3, 4, 2).contiguous()\n",
                "        \n",
                "        # 提取各部分预测\n",
                "        pred_x = torch.sigmoid(predictions[..., 0])  # 中心x偏移\n",
                "        pred_y = torch.sigmoid(predictions[..., 1])  # 中心y偏移 \n",
                "        pred_w = predictions[..., 2]                  # 宽度对数\n",
                "        pred_h = predictions[..., 3]                  # 高度对数\n",
                "        pred_conf = predictions[..., 4]               # 置信度\n",
                "        pred_cls = predictions[..., 5:]               # 类别概率\n",
                "        \n",
                "        # 简化的损失计算(演示用)\n",
                "        # 实际训练需要更复杂的target匹配逻辑\n",
                "        loss = torch.tensor(0.0, device=predictions.device, requires_grad=True)\n",
                "        \n",
                "        return loss\n",
                "\n",
                "\n",
                "print(\"YOLOv3损失函数定义完成\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. YOLOv3完整模型\n",
                "\n",
                "整合Darknet-53骨干网络和多尺度检测头。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# YOLOv3完整模型\n",
                "# ============================================================\n",
                "\n",
                "class YOLOv3(nn.Module):\n",
                "    \"\"\"YOLOv3目标检测模型\n",
                "    \n",
                "    组成:\n",
                "    1. Darknet-53骨干网络: 提取多尺度特征\n",
                "    2. 特征金字塔网络(FPN): 自顶向下融合特征\n",
                "    3. 三个检测头: 在三个尺度上检测不同大小的目标\n",
                "    \n",
                "    特点:\n",
                "    - 多尺度检测: 13x13(大目标), 26x26(中等), 52x52(小目标)\n",
                "    - 每个位置预测3个anchor box\n",
                "    - 使用Logistic回归预测置信度和类别\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, num_classes=10, img_size=416):\n",
                "        \"\"\"初始化\n",
                "        \n",
                "        Args:\n",
                "            num_classes: 类别数(CIFAR-10为10)\n",
                "            img_size: 输入图像大小(416或608)\n",
                "        \"\"\"\n",
                "        super(YOLOv3, self).__init__()\n",
                "        \n",
                "        self.num_classes = num_classes\n",
                "        self.img_size = img_size\n",
                "        \n",
                "        # YOLOv3的anchor boxes (在COCO上通过k-means聚类得到)\n",
                "        # 每个尺度3个anchor，按面积从大到小排列\n",
                "        self.anchors = [\n",
                "            [(116, 90), (156, 198), (373, 326)],  # 13x13尺度\n",
                "            [(30, 61), (62, 45), (59, 119)],       # 26x26尺度\n",
                "            [(10, 13), (16, 30), (33, 23)]         # 52x52尺度\n",
                "        ]\n",
                "        \n",
                "        # 骨干网络\n",
                "        self.backbone = Darknet53()\n",
                "        \n",
                "        # 尺度1检测头 (13x13)\n",
                "        self.head1 = YOLODetectionHead(1024, num_classes, 3)\n",
                "        \n",
                "        # 尺度1到尺度2的上采样\n",
                "        self.upsample1 = YOLOUpsample(512)  # 从head1的route通道数\n",
                "        \n",
                "        # 尺度2检测头 (26x26)\n",
                "        self.head2 = YOLODetectionHead(512 + 256, num_classes, 3)  # concat后通道\n",
                "        \n",
                "        # 尺度2到尺度3的上采样\n",
                "        self.upsample2 = YOLOUpsample(384)  # 从head2的route通道数\n",
                "        \n",
                "        # 尺度3检测头 (52x52)\n",
                "        self.head3 = YOLODetectionHead(192 + 256, num_classes, 3)\n",
                "        \n",
                "        # 损失函数\n",
                "        self.loss_fn = YOLOLoss(num_classes, self.anchors, img_size)\n",
                "    \n",
                "    def forward(self, x, targets=None):\n",
                "        \"\"\"前向传播\n",
                "        \n",
                "        Args:\n",
                "            x: 输入图像 [B, 3, 416, 416]\n",
                "            targets: 训练时的真实标注\n",
                "        Returns:\n",
                "            训练模式: 损失字典\n",
                "            推理模式: 检测结果列表\n",
                "        \"\"\"\n",
                "        # 1. 骨干网络提取多尺度特征\n",
                "        scale1, scale2, scale3 = self.backbone(x)\n",
                "        # scale1: [B, 1024, 13, 13]\n",
                "        # scale2: [B, 512, 26, 26]\n",
                "        # scale3: [B, 256, 52, 52]\n",
                "        \n",
                "        # 2. 尺度1检测 (大目标)\n",
                "        out1, route1 = self.head1(scale1)\n",
                "        \n",
                "        # 3. 上采样并与scale2融合\n",
                "        x = self.upsample1(route1, scale2)\n",
                "        \n",
                "        # 4. 尺度2检测 (中等目标)\n",
                "        out2, route2 = self.head2(x)\n",
                "        \n",
                "        # 5. 上采样并与scale3融合\n",
                "        x = self.upsample2(route2, scale3)\n",
                "        \n",
                "        # 6. 尺度3检测 (小目标)\n",
                "        out3, _ = self.head3(x)\n",
                "        \n",
                "        outputs = [out1, out2, out3]\n",
                "        \n",
                "        if self.training and targets is not None:\n",
                "            # 训练模式：计算损失\n",
                "            total_loss = torch.tensor(0.0, device=x.device, requires_grad=True)\n",
                "            for i, out in enumerate(outputs):\n",
                "                loss = self.loss_fn(out, targets, i)\n",
                "                total_loss = total_loss + loss\n",
                "            return {\"loss\": total_loss}\n",
                "        else:\n",
                "            # 推理模式：解码预测\n",
                "            return self._decode_predictions(outputs)\n",
                "    \n",
                "    def _decode_predictions(self, outputs):\n",
                "        \"\"\"解码网络输出为检测结果\n",
                "        \n",
                "        Args:\n",
                "            outputs: 三个尺度的原始输出\n",
                "        Returns:\n",
                "            检测结果: boxes, labels, scores\n",
                "        \"\"\"\n",
                "        batch_size = outputs[0].size(0)\n",
                "        all_boxes = []\n",
                "        all_scores = []\n",
                "        all_labels = []\n",
                "        \n",
                "        for scale_idx, output in enumerate(outputs):\n",
                "            grid_size = output.size(2)\n",
                "            stride = self.img_size // grid_size\n",
                "            num_anchors = 3\n",
                "            \n",
                "            # 重塑: [B, 3*(5+C), H, W] -> [B, 3, H, W, 5+C]\n",
                "            prediction = output.view(\n",
                "                batch_size, num_anchors, 5 + self.num_classes,\n",
                "                grid_size, grid_size\n",
                "            ).permute(0, 1, 3, 4, 2).contiguous()\n",
                "            \n",
                "            # 提取预测\n",
                "            x = torch.sigmoid(prediction[..., 0])  # 中心x\n",
                "            y = torch.sigmoid(prediction[..., 1])  # 中心y\n",
                "            w = prediction[..., 2]                  # 宽度\n",
                "            h = prediction[..., 3]                  # 高度\n",
                "            conf = torch.sigmoid(prediction[..., 4])  # 置信度\n",
                "            cls = torch.sigmoid(prediction[..., 5:])  # 类别\n",
                "            \n",
                "            # 获取当前尺度的anchors\n",
                "            anchors = torch.tensor(self.anchors[scale_idx], device=output.device).float()\n",
                "            anchors = anchors / stride  # 归一化到grid尺度\n",
                "            \n",
                "            # 创建网格坐标\n",
                "            grid_y, grid_x = torch.meshgrid(\n",
                "                torch.arange(grid_size, device=output.device),\n",
                "                torch.arange(grid_size, device=output.device),\n",
                "                indexing='ij'\n",
                "            )\n",
                "            \n",
                "            # 解码坐标\n",
                "            pred_boxes = torch.zeros_like(prediction[..., :4])\n",
                "            pred_boxes[..., 0] = (x + grid_x.unsqueeze(0).unsqueeze(0)) * stride\n",
                "            pred_boxes[..., 1] = (y + grid_y.unsqueeze(0).unsqueeze(0)) * stride\n",
                "            pred_boxes[..., 2] = torch.exp(w) * anchors[:, 0].view(1, -1, 1, 1) * stride\n",
                "            pred_boxes[..., 3] = torch.exp(h) * anchors[:, 1].view(1, -1, 1, 1) * stride\n",
                "            \n",
                "            # 转换为[x1,y1,x2,y2]格式\n",
                "            boxes = torch.zeros_like(pred_boxes)\n",
                "            boxes[..., 0] = pred_boxes[..., 0] - pred_boxes[..., 2] / 2\n",
                "            boxes[..., 1] = pred_boxes[..., 1] - pred_boxes[..., 3] / 2\n",
                "            boxes[..., 2] = pred_boxes[..., 0] + pred_boxes[..., 2] / 2\n",
                "            boxes[..., 3] = pred_boxes[..., 1] + pred_boxes[..., 3] / 2\n",
                "            \n",
                "            # 获取类别得分\n",
                "            cls_scores, cls_labels = cls.max(dim=-1)\n",
                "            scores = conf * cls_scores\n",
                "            \n",
                "            # 展平\n",
                "            boxes = boxes.view(batch_size, -1, 4)\n",
                "            scores = scores.view(batch_size, -1)\n",
                "            cls_labels = cls_labels.view(batch_size, -1)\n",
                "            \n",
                "            all_boxes.append(boxes)\n",
                "            all_scores.append(scores)\n",
                "            all_labels.append(cls_labels)\n",
                "        \n",
                "        # 合并所有尺度的检测\n",
                "        all_boxes = torch.cat(all_boxes, dim=1)\n",
                "        all_scores = torch.cat(all_scores, dim=1)\n",
                "        all_labels = torch.cat(all_labels, dim=1)\n",
                "        \n",
                "        # 对每张图像应用NMS\n",
                "        results = []\n",
                "        for i in range(batch_size):\n",
                "            boxes_i = all_boxes[i]\n",
                "            scores_i = all_scores[i]\n",
                "            labels_i = all_labels[i]\n",
                "            \n",
                "            # 过滤低置信度\n",
                "            mask = scores_i > 0.5\n",
                "            boxes_i = boxes_i[mask]\n",
                "            scores_i = scores_i[mask]\n",
                "            labels_i = labels_i[mask]\n",
                "            \n",
                "            if len(boxes_i) > 0:\n",
                "                # NMS\n",
                "                keep = nms(boxes_i, scores_i, 0.45)\n",
                "                boxes_i = boxes_i[keep]\n",
                "                scores_i = scores_i[keep]\n",
                "                labels_i = labels_i[keep]\n",
                "            \n",
                "            results.append({\n",
                "                \"boxes\": boxes_i,\n",
                "                \"scores\": scores_i,\n",
                "                \"labels\": labels_i\n",
                "            })\n",
                "        \n",
                "        return results\n",
                "\n",
                "\n",
                "print(\"YOLOv3完整模型定义完成\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. 训练和推理"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# 创建模型和优化器\n",
                "# ============================================================\n",
                "\n",
                "# 创建YOLOv3模型\n",
                "model = YOLOv3(num_classes=10, img_size=416).to(device)\n",
                "\n",
                "# 打印模型结构摘要\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "print(f\"总参数量: {total_params:,}\")\n",
                "print(f\"可训练参数量: {trainable_params:,}\")\n",
                "\n",
                "# 优化器: Adam with weight decay\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=5e-4)\n",
                "\n",
                "# 学习率调度器\n",
                "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
                "\n",
                "print(\"模型和优化器创建完成\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# 训练函数\n",
                "# ============================================================\n",
                "\n",
                "def train_one_epoch(model, dataloader, optimizer, device):\n",
                "    \"\"\"训练一个epoch\n",
                "    \n",
                "    Args:\n",
                "        model: YOLOv3模型\n",
                "        dataloader: 数据加载器\n",
                "        optimizer: 优化器\n",
                "        device: 计算设备\n",
                "    Returns:\n",
                "        平均损失\n",
                "    \"\"\"\n",
                "    model.train()\n",
                "    total_loss = 0\n",
                "    num_batches = 0\n",
                "    \n",
                "    for batch_idx, (images, targets) in enumerate(dataloader):\n",
                "        # 将数据移动到设备\n",
                "        images = torch.stack(images).to(device)\n",
                "        \n",
                "        # 前向传播\n",
                "        optimizer.zero_grad()\n",
                "        loss_dict = model(images, targets)\n",
                "        loss = loss_dict[\"loss\"]\n",
                "        \n",
                "        # 反向传播\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        total_loss += loss.item()\n",
                "        num_batches += 1\n",
                "        \n",
                "        if batch_idx % 100 == 0:\n",
                "            print(f\"Batch {batch_idx}/{len(dataloader)}, Loss: {loss.item():.4f}\")\n",
                "        \n",
                "        # 只训练少量batch用于演示\n",
                "        if batch_idx >= 10:\n",
                "            break\n",
                "    \n",
                "    return total_loss / num_batches\n",
                "\n",
                "\n",
                "print(\"训练函数定义完成\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# 推理函数\n",
                "# ============================================================\n",
                "\n",
                "@torch.no_grad()\n",
                "def inference(model, image, device):\n",
                "    \"\"\"对单张图像进行推理\n",
                "    \n",
                "    Args:\n",
                "        model: YOLOv3模型\n",
                "        image: 输入图像张量 [3, H, W]\n",
                "        device: 计算设备\n",
                "    Returns:\n",
                "        检测结果: boxes, scores, labels\n",
                "    \"\"\"\n",
                "    model.eval()\n",
                "    \n",
                "    # 添加batch维度\n",
                "    if image.dim() == 3:\n",
                "        image = image.unsqueeze(0)\n",
                "    \n",
                "    image = image.to(device)\n",
                "    \n",
                "    # 前向传播\n",
                "    results = model(image)\n",
                "    \n",
                "    return results[0]\n",
                "\n",
                "\n",
                "def visualize_detection(image, result, classes, threshold=0.5):\n",
                "    \"\"\"可视化检测结果\n",
                "    \n",
                "    Args:\n",
                "        image: 原始图像\n",
                "        result: 检测结果字典\n",
                "        classes: 类别名称列表\n",
                "        threshold: 置信度阈值\n",
                "    \"\"\"\n",
                "    fig, ax = plt.subplots(1, figsize=(10, 10))\n",
                "    \n",
                "    # 显示图像\n",
                "    if isinstance(image, torch.Tensor):\n",
                "        image = image.permute(1, 2, 0).numpy()\n",
                "        # 反归一化\n",
                "        mean = np.array([0.485, 0.456, 0.406])\n",
                "        std = np.array([0.229, 0.224, 0.225])\n",
                "        image = std * image + mean\n",
                "        image = np.clip(image, 0, 1)\n",
                "    \n",
                "    ax.imshow(image)\n",
                "    \n",
                "    # 绘制检测框\n",
                "    boxes = result[\"boxes\"].cpu().numpy()\n",
                "    scores = result[\"scores\"].cpu().numpy()\n",
                "    labels = result[\"labels\"].cpu().numpy()\n",
                "    \n",
                "    colors = plt.cm.hsv(np.linspace(0, 1, len(classes) + 1))\n",
                "    \n",
                "    for box, score, label in zip(boxes, scores, labels):\n",
                "        if score > threshold:\n",
                "            x1, y1, x2, y2 = box\n",
                "            width = x2 - x1\n",
                "            height = y2 - y1\n",
                "            \n",
                "            # 绘制边界框\n",
                "            rect = patches.Rectangle(\n",
                "                (x1, y1), width, height,\n",
                "                linewidth=2, edgecolor=colors[label],\n",
                "                facecolor='none'\n",
                "            )\n",
                "            ax.add_patch(rect)\n",
                "            \n",
                "            # 添加标签\n",
                "            class_name = classes[label] if label < len(classes) else f\"class_{label}\"\n",
                "            ax.text(\n",
                "                x1, y1 - 5, f\"{class_name}: {score:.2f}\",\n",
                "                color='white', fontsize=10,\n",
                "                bbox=dict(boxstyle='round', facecolor=colors[label], alpha=0.8)\n",
                "            )\n",
                "    \n",
                "    ax.axis('off')\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "\n",
                "print(\"推理和可视化函数定义完成\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# 简单训练演示\n",
                "# ============================================================\n",
                "\n",
                "print(\"开始训练演示...\")\n",
                "\n",
                "# 训练1个epoch\n",
                "avg_loss = train_one_epoch(model, train_loader, optimizer, device)\n",
                "print(f\"\\n训练完成! 平均损失: {avg_loss:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# 推理演示\n",
                "# ============================================================\n",
                "\n",
                "print(\"推理演示...\")\n",
                "\n",
                "# 获取一个测试样本\n",
                "test_images, test_targets = next(iter(test_loader))\n",
                "test_image = test_images[0]\n",
                "\n",
                "# 推理\n",
                "result = inference(model, test_image, device)\n",
                "\n",
                "print(f\"检测到 {len(result['boxes'])} 个目标\")\n",
                "print(f\"边界框: {result['boxes']}\")\n",
                "print(f\"置信度: {result['scores']}\")\n",
                "print(f\"类别: {result['labels']}\")\n",
                "\n",
                "# 可视化\n",
                "visualize_detection(test_image, result, train_dataset.classes, threshold=0.3)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
